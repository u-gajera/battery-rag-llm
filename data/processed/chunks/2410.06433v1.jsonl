{"chunk_id": "2410.06433v1_p0_c0", "doc_id": "2410.06433v1", "text": "Generative AI for Discovering Porous Oxide Materials for Next-Generation Energy Storage Joy Datta1, Amruth Nadimpally2, Nikhil Koratkar3, Dibakar Datta1,* 1Department of Mechanical and Industrial Engineering, New Jersey Institute of Technology (NJIT), Newark, NJ 07102, USA 2 Senior at John P. Stevens High School, Edison, NJ 08820, USA 3Department of Mechanical, Aerospace, and Nuclear Engineering, Rensselaer Polytechnic Institute (RPI), Troy, NY 12180, USA Corresponding Author: Dibakar Datta (dibakar.datta@njit.edu) Abstract Lithium-ion batteries (LIBs) are essential for modern applications. However, the scarcity of lithium (Li) raises concerns regarding their long-term sustainability. As a result, there is significant interest in exploring alternate battery systems utilizing earth-abundant, low-cost multivalent metals such as aluminum (Al) and calcium (Ca). The primary challenge, however, lies in identifying suitable intercalation hosts for these multivalent-ion batteries. Open-tunnel oxides, characterized by their integrated one-dimensional channels or nanopores, show great promise for facilitating effective ion transport. Yet, the wide range of compositional possibilities makes traditional experimental approaches and quantum-based models impractical for large-scale investigation. In this work, we present a generative artificial intelligence (AI) framework that employs the Crystal Diffusion Variational Autoencoder (CDVAE) and a fine-tuned Large Language Model (LLM) to accelerate the discovery of stable open-tunneled oxide materials for multivalent- ion batteries. We integrate machine learning with data mining techniques to generate five highly promising transition metal oxide (TMO) structures, known for their ability to form open-tunnel oxide frameworks, which we structurally validate using Density Functional Theory (DFT). The generated structures exhibit lower formation energies compared to analogous compositions in the Materials Project (MP) database, suggesting enhanced thermodynamic stability. We further employed the graph-based model M3GNet to relax additional generated structures, providing a computationally efficient alternative to DFT. The selection process is further refined through machine learning-based predictions of formation energy, band gap, and energy above the hull, allowing us to identify materials with significant potential for practical battery applications. This work demonstrates the efficacy of generative AI in efficiently exploring the vast chemical space of transition metal oxides (TMOs), offering a transformative approach to rapidly identify stable, open-tunneled oxides suitable for multivalent-ion batteries. Consequently, it contributes to a more sustainable", "page": 0, "position": 0}
{"chunk_id": "2410.06433v1_p1_c0", "doc_id": "2410.06433v1", "text": "1. INTRODUCTION With the growing need for high performance and sustainable energy storage systems, the development of innovative battery materials has become increasingly crucial1–3. Rechargeable batteries, especially those utilizing multivalent ions such as aluminum, calcium, magnesium, and zinc, are recognized as promising substitutes for traditional lithium-ion batteries. This transition is driven by the rising costs of rare-earth lithium and the necessity to identify plentiful, economically viable, and ecologically sustainable alternatives. However, the creation of practical multivalent-ion batteries poses considerable challenges, particularly in identifying host materials that can endure the mechanical strains caused by ion insertion while maintaining robust stability and conductivity4–7. The efficacy of battery electrodes is significantly influenced by the selection of particle size8,9. While microparticles are preferred due to their cost-effectiveness and increased volumetric energy density10, they are constrained by mechanical, thermodynamic, and kinetic limitations7,11,12. In contrast, nanoparticles provide improved cycle stability, faster charging, and shorter diffusion lengths; however, they exhibit low first-cycle efficiency, reduced volumetric capacity, and higher production costs13–15. Multiscale particles (MPs) offer a promising compromise, combining the advantages of both micro- and nanostructures. Niobium tungsten oxide (NTO) and Molybdenum vanadium oxide (MoVO) are examples of naturally porous, open-tunnel oxides that exhibit exceptional ion diffusion due to their nanoscale channels. Although these two materials exist naturally, other multiscale particles, particularly those based on transition metal oxide (TMOs), may further enhance battery performance by leveraging their unique multiscale properties16. In this context, TMO-based materials are particularly important because of their distinctive structural features, including rapid ion transport through open channels and exceptional surface area-to-volume ratios16. Given the vast range of potential TMO structures from various elemental combinations and stoichiometries, experimental exploration is infeasible, presenting a classic 'needle in a haystack' problem. Moreover, traditional computational techniques such as Density Functional Theory (DFT), although precise, are often too computationally intensive to be employed on a large scale17,18, especially when dealing with the complex structures of TMO19.Therefore, a comprehensive understanding and utilization of training data on TMO-based oxide materials are crucial for discovering and exploring new open-tunnel oxide materials to accommodate ions with multiple charges20. This effort must encompass the", "page": 1, "position": 0}
{"chunk_id": "2410.06433v1_p1_c1", "doc_id": "2410.06433v1", "text": "in a haystack' problem. Moreover, traditional computational techniques such as Density Functional Theory (DFT), although precise, are often too computationally intensive to be employed on a large scale17,18, especially when dealing with the complex structures of TMO19.Therefore, a comprehensive understanding and utilization of training data on TMO-based oxide materials are crucial for discovering and exploring new open-tunnel oxide materials to accommodate ions with multiple charges20. This effort must encompass the examination of TMO families based on binary, ternary, quaternary, quinary, and even senary configurations. In recent years, advanced Machine Learning (ML) techniques have significantly enhanced simulation speed, predictive accuracy, and the discovery of new compounds21–23. By leveraging data from Density Functional Theory (DFT) calculations and experimental techniques, ML models are trained using large databases such as the Materials Project Database (MPD)24, Automatic Flow for Materials Discovery (AFLOW)25, Inorganic Crystal Structure Database (ICSD)26 and Open Quantum Materials Database (OQMD)27. While forward ML models are effective in predicting material properties and streamlining the screening process22,28,29, they encounter difficulties to generate entirely new materials, particularly multiscale particles that combine nanoscale and microscale properties30. These multiscale structures are critical for next-generation battery technologies, underscoring the limitations of current ML approaches in innovating materials for future needs31–34. Recently, models such as CrystalGAN35, iMatGen32, and ZeoGAN36 have employed advanced machine learning techniques, including autoencoders and Generative Adversarial Networks (GANs), to generate distinct crystal structures. Generative models function by constructing a continuous latent space that encodes material data and generates new materials by mapping this latent space to desired properties, offering a potential solution to the long-standing challenge of inverse design. However, accurately", "page": 1, "position": 1}
{"chunk_id": "2410.06433v1_p2_c0", "doc_id": "2410.06433v1", "text": "translating these latent representations into real 3D structures remains challenging, limiting the practical applicability of certain generative models30. Additional issues, such as user-defined post processing, memory-intensive representations, and a lack of invariance to translation and rotation, also pose obstacles. Despite these challenges, the use of generative AI models has emerged as a potent tool in addressing these challenges by significantly expediting the discovery process30. Specifically, generative AI models have demonstrated substantial potential in material discovery by facilitating the creation of novel materials with predetermined characteristics identified by the user37–39. Through the utilization of generative AI, scientists can efficiently create and assess new materials, therefore simplifying the process of discovery and surpassing the constraints of conventional trial-and-error approaches. Among these generative models, The Crystal Diffusion Variational Autoencoder (CDVAE)37 and fine- tuned Large Language Model (LLM)40–43 represent unique approaches to material discovery. By learning the fundamental distribution of known stable materials, CDVAE can generate a wide range of realistic materials with the required periodic, rotational, and translational symmetries, excelling at constructing stable crystal structures. LLMs, on the other hand, can analyze and comprehend textual data, such as Crystallographic Information Files (CIFs), to produce supplementary structures with specific characteristics, such as porosity, tunnel structure, and conductivity41,42. By integrating the advantages of CDVAE and LLM, researchers can intensively investigate potential TMO materials, which are critical for next-generation battery technologies. Figure 1: An overview of generative AI models, such as CDVAE and a fine-tuned LLM trained on an extensive dataset from the MP database, is presented in this approach for constructing crystal structures. After verifying structural validity and ensuring uniqueness, a forward machine learning model called ALIGNN is used to predict the formation energy, energy above the hull, and band gap of these structures. The thermodynamic and electronic properties are further optimized using machine learning-based structural relaxation methods and DFT calculations to refine the structures.", "page": 2, "position": 0}
{"chunk_id": "2410.06433v1_p3_c0", "doc_id": "2410.06433v1", "text": "Our contribution to this work leverages two powerful generative AI models, CDVAE and LLM, to effectively address the challenge of discovering novel TMO based crystal structures. By combining the strengths of CDVAE and LLM, this dual strategy ensures a comprehensive exploration of potential TMO materials. CDVAE generates a broad range of plausible crystal structures, while LLM refines these structures by adding specific, desirable properties. After generating these structures, a forward machine learning model, such as the Atomistic Graph Neural Network (ALIGNN)44, is employed to predict key properties, such as formation energy, energy above the hull, and band gap. These properties are critical for assessing the thermodynamic and electronic stability of the generated materials, helping to narrow down the selection to the most promising candidates for applications in multivalent-ion batteries. The selected structures then undergo structural relaxation by Density Functional Theory (DFT) to refine their electronic structure and stability. Figure 1 illustrates the workflow. The synergy between AI models and traditional material optimization techniques ensures that the materials align with theoretical predictions and are suitable for real-world applications in advanced battery systems. 2. METHODS 2.1 Dataset Preparation: The dataset comprises 44,411 inorganic structures based on TMO materials, including binary, ternary, quaternary, quinary, and senary configurations. Robust methods were employed to analyze the structural traits of these TMO. The distribution of various TMO compositions is illustrated in Fig. 2a. Figure 2: Compositional and Atomic Distribution of TMO: (a) Data distribution by TMO composition types, (b) a detailed overview of binary TMOs, (c) an overview of ternary, quaternary, quinary, and senary TMOs, and (d) the distribution of the number of atoms presents in the collected MP dataset. In panels (b)", "page": 3, "position": 0}
{"chunk_id": "2410.06433v1_p4_c0", "doc_id": "2410.06433v1", "text": "and (c), materials included in the study are highlighted in green, while excluded materials are shown in red. The uncolored areas in (c) represent the third, fourth, fifth, and sixth components in ternary, quaternary, quinary, and senary TMOs, respectively. An example of a quaternary TMO is represented by the formula WsArBmOn, where W and A represent any metal from the periodic table, and B is a transition metal. The letters s, r, m, and n denote the stoichiometric ratios. For the ML model, 60% of the data was allocated for training, 20% for testing, and the remaining 20% for validation. Due to the importance of transition metals in battery materials research, our study focused on these elements. Notably, ternary TMOs constitute approximately 26,393 data points, while senary TMO are underrepresented, with only 37 entries (Fig. 2a). The data were obtained from the Materials Project (MP)45 database through the API using the Python libraries Matminer46 and Pymatgen47. Fig. 2d shows the distribution of the number of atoms per composition, with a maximum of fewer than 45 atoms considered in the analysis. The entire dataset was divided into three partitions for our ML model: 60% for training, 20% for testing, and the remaining 20% for validation. 2.2 Crystal Diffusion Variational Autoencoder (CDVAE) The CDVAE generative model uses an empirical distribution of known stable materials to learn and produce stable material structures by combining the functionalities of Variational Autoencoders (VAE) and Diffusion models37. The model's architecture comprises three primary components: an encoder, an attribute predictor, and a decoder. The encoder, PGNNENC, employs a SE(3)-equivariant periodic graph neural network (PGNN) to transform input data comprising atomic types, atomic coordinates, and a periodic lattice into a lower-dimensional latent space vector z. Maintaining periodic boundaries and respecting symmetries are crucial for accurately representing materials in the latent space48–50. Once the latent vector z is generated, the attribute predictor estimates three key properties of the material: composition (c), lattice (L), and the number of atoms (N). These predictions are made using multilayer perceptrons (MLPs), each utilizing a different loss function tailored to the property being predicted. Cross-", "page": 4, "position": 0}
{"chunk_id": "2410.06433v1_p4_c1", "doc_id": "2410.06433v1", "text": "a lower-dimensional latent space vector z. Maintaining periodic boundaries and respecting symmetries are crucial for accurately representing materials in the latent space48–50. Once the latent vector z is generated, the attribute predictor estimates three key properties of the material: composition (c), lattice (L), and the number of atoms (N). These predictions are made using multilayer perceptrons (MLPs), each utilizing a different loss function tailored to the property being predicted. Cross- entropy loss is applied for composition prediction, ensuring the model correctly predicts the ratios of different atom types. For lattice prediction, the model reduces the lattice to six unique, rotation-invariant parameters using the Niggli algorithm51, which ensures the lattice structure is accurately captured and represented. The L2 loss function is used to minimize the error in this prediction. For the number of atoms, softmax activation is applied, allowing the model to output a probability distribution over a set of possible atom counts. The decoder, PGNNDEC, employs Langevin dynamics to reconstruct the material structure from the noisy latent representation. The denoising process iteratively refines atomic types and coordinates to ensure the local and global stability of the created material. The decoder is designed to be SE(3)- equivariant, preserving the material's periodic, rotational, and translational symmetries of the material throughout the denoising process37. During training in the VAE framework, the Kullback-Leibler (KL) Divergence Loss (LKL) ensures that the latent space z adheres to a normal Gaussian distribution, which is essential for the generative process. This smooth interpolation in the latent space allows for efficient sampling of new materials. The KL divergence loss regularizes the latent space by minimizing the difference between the learned latent distribution q(z∣M) and a standard Gaussian distribution p(z), ensuring the model generalizes well for material generation.", "page": 4, "position": 1}
{"chunk_id": "2410.06433v1_p5_c0", "doc_id": "2410.06433v1", "text": "Throughout training, the CDVAE model minimizes three primary loss functions: the Aggregated Property Loss (LAGG), which evaluates the accuracy of predictions for composition, lattice, and atom count; the Decoder Denoising Loss (LDEC), which ensures the decoder accurately reconstructs stable material structures; and the KL Divergence Loss (LKL), which regularizes the latent space. After training, the model can select a latent vector z, predict the material’s aggregated properties, and initialize an arbitrary material structure to generate new materials. The model applies Langevin dynamics to iteratively refine the structure by adjusting atom types and their positions until a stable material is formed. A significant innovation in CDVAE is the incorporation of a harmonic force field into the learned gradient field48. This integration introduces a physically meaningful inductive bias, allowing for a better approximation of quantum mechanical forces. This process ensures the generation of stable and realistic materials. By employing a well-regularized latent space, noise conditioning, and respect for physical symmetries, CDVAE generates stable, diverse, and accurate materials, making it a powerful tool for material discovery37,52, particularly in applications like battery materials. The architecture of CDVAE model is shown Fig. 3. Figure 3: Architecture of the CDVAE Model for Generating Stable Material Structures: The model combines a SE(3)-equivariant periodic graph neural network (PGNN) encoder, an attribute predictor, and an SE(3)-equivariant decoder using Langevin dynamics. The encoder maps atomic types, coordinates, and lattice information into a latent space, from which the attribute predictor estimates composition, lattice parameters, and atom count. The decoder refines noisy latent representations through iterative denoising to generate physically stable materials, ensuring periodic and symmetrical properties are maintained. 2.3 Fine tuning large language model The architecture of the Large Language Model (LLM) used in crystal material generation leverages the pre- trained LLaMA-3.1 (8B parameter) model with Unsloth for fine-tuning40. Unsloth accelerates the fine- tuning process by 2.1x and reduces memory usage by 60% compared to alternatives such as Flash Attention", "page": 5, "position": 0}
{"chunk_id": "2410.06433v1_p6_c0", "doc_id": "2410.06433v1", "text": "2 (FA2)53 paired with Hugging Face (HF)54. This fine-tuning strategy improves training efficiency while lowering computational costs. The process begins with transforming crystal structures into a format compatible with the language model, represented as a tuple of lattice vectors, angles, atomic identities, and coordinates. This data is then tokenized into sequences, with each digit of the numerical values tokenized separately. The pre-trained LLaMA-3.1 model, originally designed for natural language tasks, is adapted for atomic structure prediction using LoRA (Low Rank Adaptation)55, reducing the need to retrain the entire model while maintaining high accuracy. The model can handle various generation tasks, including unconditional synthesis of new crystal structures, text-conditional generation based on material properties, and infilling to modify existing structures. To capture symmetries in crystal structures, data augmentations are applied during training, ensuring that the model learns translation and permutation invariance without requiring special architectural modifications43,56. Hyperparameters such as temperature and nucleus size are adjusted during generation process to balance randomness and stability in the resulting crystal structures. Our approach of leveraging the LLM model through fine-tuning is illustrated in Fig. 4. Figure 4: Overview of fine-tuning LLaMA 3.1 (8B) model for generating crystal structures. LoRA involves training only a subset of the model parameters (i.e., the low-rank matrices) to adapt the pre-trained model to crystal generation task. 2.4 Atomistic graph neural network (ALIGNN): For our forward ML, we choose the ALIGNN model44,57. By fusing bond and line graph structures, the ALIGNN model enhances atomic and bond representations through a unique graph convolution approach. Bond graphs, similar to traditional atomistic models, represent atoms as nodes and bonds as edges, while line graphs represent bonds as nodes and connect pairs of bonds that share a common atom. This distinctive", "page": 6, "position": 0}
{"chunk_id": "2410.06433v1_p7_c0", "doc_id": "2410.06433v1", "text": "arrangement improves the aggregation of bond-specific data, allowing for more accurate updates to atomic and bond level representations. To incorporate angular information, ALIGNN constructs the line graph from the bond graph by transforming bonds into nodes and defining edge characteristics using radial basis function (RBF) expansions of bond angle cosine values. With the inclusion of this angular data, the model can better predict material properties by capturing finer details of atomic structures. The model’s primary goal is to accurately represent the complex bond-atom interactions in crystalline materials. By efficiently transferring information between the bond and line graphs, ALIGNN improves the prediction of material properties, utilizing edge-gated graph convolution and angular information to effectively capture key structural features that influence the behavior of crystalline materials58. 2.5 M3GNet model: M3GNet is a graph-based deep learning model that utilizes Interatomic Potential (IAP) to provide a highly effective and precise alternative to Density Functional Theory (DFT) in predicting relaxed energies of materials59. It employs Graph Neural Network (GNN) to represent materials as mathematical graphs, with atoms serving as nodes and the connections between them as edges. The architecture of M3GNet effectively captures many-body interactions and accurately represents the Potential Energy Surface (PES). Through iterative graph convolution processes, M3GNet enhances the accuracy of energy, force, and stress predictions by updating bond, atom, and global state information. In contrast to DFT, which is characterized by high computational costs and reduced scalability with system size, M3GNet offers a faster, linear-scaling approach without compromising accuracy52. The M3GNet model, trained on a comprehensive dataset from the MP database, has strong generalization capabilities across a diverse array of chemistries and crystal structures. Its demonstrated ability to efficiently relax millions of theoretical structures makes it a highly suitable tool for large-scale material exploration. In this context, the relaxed energies of 55 produced structures were computed using M3GNet, offering a cost- effective alternative to DFT for efficient energy reduction and reliable material identification. 2.6 DFT Relaxation: For the relaxation of generated selected crystal structures, we integrated the Projector Augmented Wave (PAW) approach into the Vienna Ab initio Simulation Software (VASP) and conducted", "page": 7, "position": 0}
{"chunk_id": "2410.06433v1_p8_c0", "doc_id": "2410.06433v1", "text": "where 𝑛# is the concentration of single atom. The Gibbs free energy, D𝐺, is defined as: D𝐺= D𝐸#+PD𝑉#-TD𝑆# (2) In equation (2), at room temperature, PD𝑉# and TD𝑆# are negligible compared to D𝐸# 8. The formation energy, D𝐸# ,can be computed using the equation: D𝐸#= D𝐸$%$&'- (∑𝑛𝑖𝐸𝑖) (3) where 𝐸$%$&' is the Gibbs free energy of the generated TMO-based crystal structure. ni, is the number of atoms of element i in the TMO structure. Ei is the Gibbs free energy of the elemental form of atom i. A negative value of D𝐸# indicates that the compound is thermodynamically stable relative to its constituent elements. 3. RESULTS AND DISCUSSION The CDVAE model is configured for efficient performance, using a latent dimension of 256 and hidden layers between 128 and 256 dimensions. It employs a GemNet-dQ60 as the decoder, with a 7.0 Å radius and a maximum of 20 neighbors per atom. Langevin dynamics48 refines noisy structures by improving atomic positions and bond preferences with diffusion parameters such as 𝜎()*+\" = 10.0 and 𝜎)\", = 0.01. The loss function is optimized using weighted costs for several model characteristics, including coordination (cost coord=10), atom types (cost type=1), and lattice stability (cost lattice=10). High-cost values, such as 10 for coordination and lattice stability, indicate that the model emphasizes these features for precise structure formation during training. To balance convergence speed and stability, the learning rate is initially set to 0.001 with a minimum value of 0.0001, preventing overshooting and stalling during training by allowing efficient parameter updates. The Niggli-reduced lattice51 ensures unique lattice prediction, while CrystalNN61 and KNN algorithms capture periodicity and atom-atom interactions. The model is SE(3) invariant, with DimeNet++62 serving as the encoder, ensuring robustness against rotational, translational, and periodic boundary conditions. We utilize an L40 architecture with 48 GB VRAM, 250 GB RAM, and 16 vCPUs for training the CDVAE model on our customized CIF dataset. For our CDVAE model, training for 5000 epochs took approximately 60 hours, demonstrating its computationally efficiency and speed. The CDVAE model generated 10000 structures, which were subjected to a series of precise screening and validation", "page": 8, "position": 0}
{"chunk_id": "2410.06433v1_p8_c1", "doc_id": "2410.06433v1", "text": "encoder, ensuring robustness against rotational, translational, and periodic boundary conditions. We utilize an L40 architecture with 48 GB VRAM, 250 GB RAM, and 16 vCPUs for training the CDVAE model on our customized CIF dataset. For our CDVAE model, training for 5000 epochs took approximately 60 hours, demonstrating its computationally efficiency and speed. The CDVAE model generated 10000 structures, which were subjected to a series of precise screening and validation steps to ensure they met the necessary standards. The first step involved verifying that each structure satisfied important performance criteria, considering both structural soundness and compositional balance. For structural verification, we applied the method suggested by Court et al.63, which checks the distance between atom pairs to ensure no atoms are closer than 0.5 Å. This method focuses solely on the distance between atoms, ignoring other factors. For composition, we used the SMACT method to verify charge neutrality. If the SMACT data indicates that the material has an overall neutral charge, it is considered compositionally correct. We then filtered out generated crystal structures already present in the MP database by checking for similar compositions. After applying these filters for structural and compositional validity, and ensuring uniqueness, 8203 out of the 10000 structures passed the initial screening.", "page": 8, "position": 1}
{"chunk_id": "2410.06433v1_p9_c0", "doc_id": "2410.06433v1", "text": "Next, we aimed to identify materials with desirable properties using a forward ML approach named ALIGNN to predict the formation energy/atom, band gap, and energy above hull. For our forward ML model, we have predicted all the property with pretrained ALIGNN model. We selected a formation energy baseline of -1.5 eV/atom, as lower values indicate higher synthesizability and stability for battery materials, following Ren et al.38 criteria for energy applications. For band gap, the lower band gap has high probability to utilize into battery applications due to its high conductivity64,65. Therefore, we selected structures with a band gap less than or equal to 0.5 eV/atom. Lastly, the most important property of ensuring stability is to choose the energy above hull. Kim et. al30 considered less than 0.08 eV/atom energy above hull as a standard margin to consider any generated material to be stable and synthesizable. Therefore, our study follows the same approach. After applying these property-based filters, we retrieved 42 structures from the CDVAE approach, guided by their potential to expand battery material discovery. The selection included 5 oxygen-containing structures and 37 oxygen-free structures. Of these, 21 structures matched existing entries in the MP database but offered new configurations with differences in stoichiometry, lattice parameters, or space groups, The remaining 21 structures were entirely novel. Despite being oxygen-free, the 37 structures were generated using TMO-trained models, inheriting key beneficial features associated with energy storage applications. These oxygen-free structures demonstrate notable compositional and structural diversity, which could give rise to unique ionic diffusion pathways, improved electronic conductivity, and increased structural stability - key properties typically associated with TMO-based battery materials. Figure 5: Overview of the top 5 most stable structures generated by the CDVAE model, ranked by energy above hull (eV/atom).", "page": 9, "position": 0}
{"chunk_id": "2410.06433v1_p10_c0", "doc_id": "2410.06433v1", "text": "It is essential to recognize that non-oxide materials, particularly those containing transition metals, may offer valuable advantages due to their ability to accommodate multiple ions while maintaining good conductivity66,67. Given that the generated structures retain critical characteristics of TMO-based materials, they are strong candidates for further investigation. Predictions using the ALIGNN model indicate that these 42 structures satisfy essential stability and performance benchmarks, underscoring the value of both oxygen-containing and oxygen-free candidates in advancing battery technologies. This approach not only capitalizes on the established strengths of TMO systems but also opens up promising new avenues for material discovery and innovation in the development of next-generation energy storage solutions. Out of these 42 structures, we present the 5 most stable structures, as predicted by the ALIGNN model based on energy above the hull, shown in Fig. 5. For fine-tuning the LLM model, this study calibrates the Meta-Llama-3.1-8B model using a parameter- efficient method specifically tailored for generating crystal structures. The Low-Rank Adaptation (LoRA) technique is employed to minimize computational burden without compromising performance. The algorithm is configured with a rank of 8, an alpha of 32, and a dropout rate of 0.05. These parameters are selected to achieve optimal model performance on hardware with limited resources. Additionally, 4-bit quantization is used to reduce memory consumption while maintaining the precision of the process. Figure 6: Overview of the top 5 most stable structures generated by the LLM model, ranked by energy above hull (eV/atom). Material parameters such as formation energy, band gap, and energy above hull are represented by tokenized sequences derived from CIF. The model performs tasks such as generating entire structures, property-based conditional generation, and infilling missing components. To accommodate the model's size and complexity, training is conducted with a batch size of 1 and gradient accumulation of 1. A learning rate of 1×10−4, along with a cosine scheduler and 100 warmup steps, is used to ensure stability. The model is", "page": 10, "position": 0}
{"chunk_id": "2410.06433v1_p11_c0", "doc_id": "2410.06433v1", "text": "trained for 25 epochs, with periodic checkpoints and assessments carried out during the process. We utilized the same GPU architecture for training the fine-tuned LLM model. Despite the model being quantized, the training process took 150 hours, demonstrating that even with optimizations, fine-tuning large language models remains computationally expensive. Our fine-tuned LLM model generated 10000 structures according to the specified instructions. After applying compositional, structural validity, and uniqueness checks, 1087 structures remained. We then employed a similar forward machine learning approach to filter these structures based on the three properties mentioned earlier. Following this filtration, only 18 structures passed the criteria. In the case of the LLM model, all 18 final structures are oxygen-free, consistent with the rationale of the CDVAE model discussed earlier. Despite the absence of oxygen, these structures retain key properties typically associated with TMO due to the model being trained entirely on TMO data. Out of these 18 structures, 16 are present in the MP database but show differences in elemental ratios, crystal dimensions, or symmetry classifications, while the remaining 2 structures are entirely novel, presenting new opportunities for material design. The five most stable structures, selected based on their lowest energy above the hull, are presented in Fig. 6. Fig. 7 illustrates the distribution of key material properties, including formation energy, band gap, and energy above the hull, for both the CDVAE and LLM models. For the CDVAE model, the formation energy (Fig. 7a) ranges from approximately -3.83 eV/atom to -1.73 eV/atom, indicating that the model produces more energetically stable structures. The most stable structure has a formation energy of -3.83 eV/atom, suggesting that the CDVAE model can generate highly stable materials. The band gap distribution (Fig. 7b) covers a range of -0.09 eV to 0.49 eV, indicating moderate variability in the electronic properties of the generated structures. The energy above the hull (Fig. 7c) ranges from -0.07 eV/atom to 0.08 eV/atom, signifying the relative stability of the structures, with the potential for generating both stable and metastable structures.", "page": 11, "position": 0}
{"chunk_id": "2410.06433v1_p12_c0", "doc_id": "2410.06433v1", "text": "Figure 7: Property distribution of filtered structures before relaxation: Data distribution of formation energy (eV/atom), band gap (eV), and energy above hull (eV/atom) for the (a-c) CDVAE and (d-f) LLM model. The CDVAE model generates more diverse and stable structures compared to the LLM model, with the most stable structure having a formation energy of -3.85 eV/atom. In comparison, the LLM model (Fig. 7d-f) displays a narrower distribution of formation energy, ranging from -2.92 eV/atom to -2.02 eV/atom, with fewer energetically stable structures compared to the CDVAE model. The band gap distribution (Fig. 7e) spans from -0.08 eV to 0.08 eV, reflecting limited diversity in electronic properties. The energy above the hull for the LLM model (Fig. 7f) ranges from -0.03 eV/atom to 0.06 eV/atom. While this is comparable to the CDVAE model, it suggests that the LLM model generates fewer highly stable structures overall. These results demonstrate that the CDVAE model outperforms the LLM model in terms of stability, as reflected by its lower formation energy and energy above the hull. This highlights its ability to generate more stable and diverse structures compared to the LLM model, which exhibits a narrower range of property distributions and produces less stable configurations. For structural relaxation, the M3GNet model was applied to all 42 filtered structures from the CDVAE model, while only 13 out of 18 filtered structures from the LLM model successfully optimized. This highlights the CDVAE model's ability to generate more stable structures. Fig. 8 compares the relaxed energy distributions of both models. The CDVAE model (Fig. 8a) produces a wider range of relaxed energies, with several structures achieving lower energy values down to -6.28 eV/atom, indicating greater stability. In contrast, the LLM model (Fig. 8b) shows a narrower distribution, with the most stable structure having a relaxed energy of around -4.92 eV/atom. These findings confirm the CDVAE model's superiority in generating more diverse and stable structures after relaxation. Figure 8: Relaxed energy distribution of generated structures using the M3GNet model: (a) 42 crystal structures generated by the CDVAE model, and (b) 13 crystal structures generated by the LLM model.", "page": 12, "position": 0}
{"chunk_id": "2410.06433v1_p13_c0", "doc_id": "2410.06433v1", "text": "applications, such as their ability to enhance ionic conductivity, structural stability, and multivalent ion accommodation. Given the importance of TMO materials for high-performance multivalent-ion batteries, it is essential to validate and thoroughly analyze the TMO structures generated by the CDVAE model. By performing DFT calculations, we ensured the structural and thermodynamic stability of these materials, confirming their suitability for real-world applications. All five structures successfully relaxed during the DFT process. Next, we calculated the formation energies for these five compositions using equation (3). The required individual atomic energies for the calculation were also determined using DFT. Fig. 9 compares the formation energies per atom between our generated structures and the corresponding structures from the MP database, where available. These five TMO-based structures (Fig.10), feature large open-tunnel frameworks designed to enhance ion transport by accommodating multivalent ions. Their interconnected channels make them promising candidates for high-performance multivalent-ion batteries, offering both structural stability and efficient ion diffusion pathways. We confirm that three out of the five compositions are present in the MP database, albeit with different stoichiometry ratios. For comparison, we selected the most stable composition from the MP database based on their energy above the hull values and extracted their formation energies. As shown in Fig. 9, the generated structures demonstrate superior stability, as reflected by their lower formation energy per atom compared to the MP database counterparts. For instance, the formation energy of generated Mg2Cu2O4F4 is about -1.8 eV/atom, while the corresponding MP database structure has a formation energy of -1.6 eV/atom. Similarly, for Ca2OIn, the generated structure exhibits a significantly lower formation energy of -6.5 eV/atom compared to -3.0 eV/atom for the MP database equivalent. These comparisons further illustrate the enhanced stability of the generated structures relative to their MP database counterparts. Figure 9: Comparison of formation energy per atom for generated TMO structures versus MP database entries. The generated structures exhibit lower formation energies, indicating higher stability compared to their MP database counterparts.", "page": 13, "position": 0}
{"chunk_id": "2410.06433v1_p14_c0", "doc_id": "2410.06433v1", "text": "Figure 10: Overview of five TMO-based structures generated by the CDVAE model, highlighting large open-tunnel frameworks designed for efficient accommodation of multivalent ions in battery applications. 4. CONCLUSION In this study, we demonstrate the efficacy of combining generative AI models—CDVAE and fine-tuned LLM—to address the challenges of discovering novel TMO-based materials for multiscale batteries. Five of the generated structures satisfy the requirements for open-tunnel oxide frameworks, which are essential for efficient ion transport in multivalent-ion battery systems. Due to their interconnected one-dimensional channels and nanopores, these TMO-based structures show great promise as battery materials. The CDVAE model, which specializes in generating stable crystal structures, successfully created five TMO compositions, all of which were structurally confirmed using DFT relaxation. Our comparison with the MP database reveals that the generated structures have lower formation energies than their MP counterparts, indicating higher stability. For instance, the structure of Ca₂OIn exhibits a much lower formation energy (-6.5 eV/atom) compared to the MP database's -3.0 eV/atom. We find that the CDVAE model outperforms the LLM in terms of structural stability and variety. One reason the LLM model underperforms is that it was trained on a 4-bit quantized model, which may have limited its capacity to generate highly stable structures. We anticipate that increasing the quantization to an 8-bit model could enhance its performance and enable the generation of more stable structures. Our future direction includes exploring other open-source models to discover additional TMO-based materials. Our findings underscore the potential of generative AI in accelerating the identification of stable, open- tunnel TMO materials, which are essential for the development of next-generation multivalent-ion batteries. The combination of AI-driven models and traditional computational approaches offers a transformative method for material discovery, significantly reducing the time and computational costs typically associated with trial-and-error experiments. This framework presents a novel approach for discovering stable and efficient materials for sustainable energy storage devices.", "page": 14, "position": 0}
{"chunk_id": "2410.06433v1_p15_c0", "doc_id": "2410.06433v1", "text": "AUTHOR INFORMATION Corresponding Author Dibakar Datta Email: dibakar.datta@njit.edu ; Phone: +1 973 596 3647 Author Contributions J.D., D.D. and N.K. conceived the project. J.D. performed all work and wrote the manuscript with D.D. and N.K. A. N. helped J.D. with calculations. All authors approved the final version of the manuscript. CONFLICT OF INTEREST STATEMENT The authors have no conflicts of interest to declare. All authors have seen and agree with the contents of the manuscript and there is no financial interest to report. We certify that the submission is original work and is not under review at any other publication. ACKNOWLEDGEMENT The work is supported by National Science Foundation (NSF) (Award Number #2237990). Authors acknowledge Advanced Cyberinfrastructure Coordination Ecosystem: Service & Support (ACCESS) for the computational facilities (Award Number - DMR180013). DATA AVAILABILITY Data can be obtained by requesting the corresponding author. CODE AVAILABILITY Code for extracting the data and its training model is available on GitHub (https://github.com/joy1303125/Generative-AI-for-battery-material), providing researchers in the field with a valuable resource. Restrictions apply to the availability of the simulation codes, which were used under license for this study. REFERENCES: (1) Yoo, H. D.; Shterenberg, I.; Gofer, Y.; Gershinsky, G.; Pour, N.; Aurbach, D. Mg Rechargeable Batteries: An on-Going Challenge. Energy Environ. Sci. 2013, 6 (8), 2265–2279. (2) Elia, G. A.; Marquardt, K.; Hoeppner, K.; Fantini, S.; Lin, R.; Knipping, E.; Peters, W.; Drillet, J.; Passerini, S.; Hahn, R. An Overview and Future Perspectives of Aluminum Batteries. Adv. Mater.", "page": 15, "position": 0}
{"chunk_id": "2410.06433v1_p16_c0", "doc_id": "2410.06433v1", "text": "2016, 28 (35), 7564–7579. (3) Muldoon, J.; Bucur, C. B.; Gregory, T. Quest for Nonaqueous Multivalent Secondary Batteries: Magnesium and Beyond. Chem. Rev. 2014, 114 (23), 11683–11720. (4) Gummow, R. J.; Vamvounis, G.; Kannan, M. B.; He, Y. Calcium‐ion Batteries: Current State‐of‐ the‐art and Future Perspectives. Adv. Mater. 2018, 30 (39), 1801702. (5) Ponrouch, A.; Palacin, M. R. On the Road toward Calcium-Based Batteries. Curr. Opin. Electrochem. 2018, 9, 1–7. https://doi.org/10.1016/j.coelec.2018.02.001. (6) Lakhnot, A. S.; Panchal, R. A.; Datta, J.; Mahajani, V.; Bhimani, K.; Jain, R.; Datta, D.; Koratkar, N. Intercalation Hosts for Multivalent‐Ion Batteries. Small Struct. 2022, 2200290, 2200290. https://doi.org/10.1002/sstr.202200290. (7) Naik, K. G.; Vishnugopi, B. S.; Datta, J.; Datta, D.; Mukherjee, P. P. Electro-Chemo-Mechanical Challenges and Perspective in Lithium Metal Batteries. Appl. Mech. Rev. 2023, 75 (1), 10802. (8) Chu, S.; Cui, Y.; Liu, N. The Path towards Sustainable Energy. Nat. Mater. 2017, 16 (1), 16–22. (9) Chu, S.; Majumdar, A. Opportunities and Challenges for a Sustainable Energy Future. Nature 2012, 488 (7411), 294–303. (10) Whittingham, M. S. History, Evolution, and Future Status of Energy Storage. Proc. IEEE 2012, 100 (Special Centennial Issue), 1518–1534. (11) Jain, R.; Lakhnot, A. S.; Bhimani, K.; Sharma, S.; Mahajani, V.; Panchal, R. A.; Kamble, M.; Han, F.; Wang, C.; Koratkar, N. Nanostructuring versus Microstructuring in Battery Electrodes. Nat. Rev. Mater. 2022, 7 (9), 736–746. https://doi.org/10.1038/s41578-022-00454-9. (12) Datta, J.; Datta, D.; Sharma, V. Transferable and Robust Machine Learning Model for Predicting Stability of Si Anodes for Multivalent Cation Batteries. J. Mater. Sci. 2023, 58 (27), 11085– 11099. https://doi.org/10.1007/s10853-023-08705-y. (13) Qi, W.; Shapter, J. G.; Wu, Q.; Yin, T.; Gao, G.; Cui, D. Nanostructured Anode Materials for Lithium-Ion Batteries: Principle, Recent Progress and Future Perspectives. J. Mater. Chem. A 2017, 5 (37), 19521–19540. (14) Graetz, J.; Ahn, C. C.; Yazami, R.; Fultz, B. Highly Reversible Lithium Storage in Nanostructured Silicon. Electrochem. Solid-State Lett. 2003, 6 (9), A194. (15) Liu, X. H.; Zhong, L.; Huang, S.; Mao, S. X.; Zhu, T.; Huang, J. Y. Size-Dependent Fracture of Silicon Nanoparticles during Lithiation. ACS Nano 2012, 6 (2), 1522–1531. (16) Banerjee, S.; De, B.; Sinha, P.; Cherusseri,", "page": 16, "position": 0}
{"chunk_id": "2410.06433v1_p17_c0", "doc_id": "2410.06433v1", "text": "(20) Rao, C. N. R.; Rao, G. V. S. Transition Metal Oxides:: Crystal Chemistry, Phase Transition, and Related Aspects. 1974. (21) Xie, T.; Grossman, J. C. Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties. Phys. Rev. Lett. 2018, 120 (14), 145301. https://doi.org/10.1103/PhysRevLett.120.145301. (22) Louis, S.-Y.; Zhao, Y.; Nasiri, A.; Wang, X.; Song, Y.; Liu, F.; Hu, J. Graph Convolutional Neural Networks with Global Attention for Improved Materials Property Prediction. Phys. Chem. Chem. Phys. 2020, 22 (32), 18141–18148. (23) Jiang, D.; Wu, Z.; Hsieh, C. Y.; Chen, G.; Liao, B.; Wang, Z.; Shen, C.; Cao, D.; Wu, J.; Hou, T. Could Graph Neural Networks Learn Better Molecular Representation for Drug Discovery? A Comparison Study of Descriptor-Based and Graph-Based Models. J. Cheminform. 2021, 13 (1), 1– 23. https://doi.org/10.1186/s13321-020-00479-8. (24) Jain, A.; Ong, S. P.; Hautier, G.; Chen, W.; Richards, W. D.; Dacek, S.; Cholia, S.; Gunter, D.; Skinner, D.; Ceder, G. Commentary: The Materials Project: A Materials Genome Approach to Accelerating Materials Innovation. APL Mater. 2013, 1 (1), 11002. (25) Curtarolo, S.; Setyawan, W.; Hart, G. L. W.; Jahnatek, M.; Chepulskii, R. V; Taylor, R. H.; Wang, S.; Xue, J.; Yang, K.; Levy, O. AFLOW: An Automatic Framework for High-Throughput Materials Discovery. Comput. Mater. Sci. 2012, 58, 218–226. (26) Karlsruhe, F. Inorganic Crystal Structure Database. URL http//icsd. fiz-karlsruhe. de. Acessed 2014, 12. (27) Kirklin, S.; Saal, J. E.; Meredig, B.; Thompson, A.; Doak, J. W.; Aykol, M.; Rühl, S.; Wolverton, C. The Open Quantum Materials Database (OQMD): Assessing the Accuracy of DFT Formation Energies. npj Comput. Mater. 2015, 1 (October). https://doi.org/10.1038/npjcompumats.2015.10. (28) Xie, T.; Grossman, J. C. Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties. Phys. Rev. Lett. 2018, 120 (14), 145301. (29) Chen, C.; Ye, W.; Zuo, Y.; Zheng, C.; Ong, S. P. Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals. Chem. Mater. 2019, 31 (9), 3564–3572. (30) Kim, S.; Noh, J.; Gu, G. H.; Aspuru-Guzik, A.; Jung, Y. Generative Adversarial Networks for Crystal Structure Prediction. ACS Cent. Sci. 2020, 6 (8), 1412–1420. (31) Zunger,", "page": 17, "position": 0}
{"chunk_id": "2410.06433v1_p17_c1", "doc_id": "2410.06433v1", "text": "Interpretable Prediction of Material Properties. Phys. Rev. Lett. 2018, 120 (14), 145301. (29) Chen, C.; Ye, W.; Zuo, Y.; Zheng, C.; Ong, S. P. Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals. Chem. Mater. 2019, 31 (9), 3564–3572. (30) Kim, S.; Noh, J.; Gu, G. H.; Aspuru-Guzik, A.; Jung, Y. Generative Adversarial Networks for Crystal Structure Prediction. ACS Cent. Sci. 2020, 6 (8), 1412–1420. (31) Zunger, A. Inverse Design in Search of Materials with Target Functionalities. Nat. Rev. Chem. 2018, 2 (4), 121. (32) Noh, J.; Kim, J.; Stein, H. S.; Sanchez-Lengeling, B.; Gregoire, J. M.; Aspuru-Guzik, A.; Jung, Y. Inverse Design of Solid-State Materials via a Continuous Representation. Matter 2019, 1 (5), 1370–1384. (33) Schmidt, J.; Marques, M. R. G.; Botti, S.; Marques, M. A. L. Recent Advances and Applications of Machine Learning in Solid-State Materials Science. npj Comput. Mater. 2019, 5 (1), 83. (34) Weiss, T.; Mayo Yanes, E.; Chakraborty, S.; Cosmo, L.; Bronstein, A. M.; Gershoni-Poranne, R. Guided Diffusion for Inverse Molecular Design. Nat. Comput. Sci. 2023, 3 (10), 873–882. (35) Nouira, A.; Sokolovska, N.; Crivello, J. C. CrystalGAN: Learning to Discover Crystallographic Structures with Generative Adversarial Networks. CEUR Workshop Proc. 2019, 2350 (Umr 7182). (36) Kim, B.; Lee, S.; Kim, J. Inverse Design of Porous Materials Using Artificial Neural Networks.", "page": 17, "position": 1}
{"chunk_id": "2410.06433v1_p18_c0", "doc_id": "2410.06433v1", "text": "Sci. Adv. 2020, 6 (1), eaax9324. (37) Xie, T.; Fu, X.; Ganea, O.-E.; Barzilay, R.; Jaakkola, T. Crystal Diffusion Variational Autoencoder for Periodic Material Generation. arXiv Prepr. arXiv2110.06197 2021. (38) Ren, Z.; Tian, S. I. P.; Noh, J.; Oviedo, F.; Xing, G.; Li, J.; Liang, Q.; Zhu, R.; Aberle, A. G.; Sun, S. An Invertible Crystallographic Representation for General Inverse Design of Inorganic Crystals with Targeted Properties. Matter 2022, 5 (1), 314–335. (39) Dan, Y.; Zhao, Y.; Li, X.; Li, S.; Hu, M.; Hu, J. Generative Adversarial Networks (GAN) Based Efficient Sampling of Chemical Composition Space for Inverse Design of Inorganic Materials. npj Comput. Mater. 2020, 6 (1), 1–7. https://doi.org/10.1038/s41524-020-00352-0. (40) Gruver, N.; Sriram, A.; Madotto, A.; Wilson, A. G.; Zitnick, C. L.; Ulissi, Z. Fine-Tuned Language Models Generate Stable Inorganic Materials as Text. arXiv Prepr. arXiv2402.04379 2024. (41) Hadi, M. U.; Al Tashi, Q.; Shah, A.; Qureshi, R.; Muneer, A.; Irfan, M.; Zafar, A.; Shaikh, M. B.; Akhtar, N.; Wu, J. Large Language Models: A Comprehensive Survey of Its Applications, Challenges, Limitations, and Future Prospects. Authorea Prepr. 2024. (42) Minaee, S.; Mikolov, T.; Nikzad, N.; Chenaghlu, M.; Socher, R.; Amatriain, X.; Gao, J. Large Language Models: A Survey. arXiv Prepr. arXiv2402.06196 2024. (43) Antunes, L. M.; Butler, K. T.; Grau-Crespo, R. Crystal Structure Generation with Autoregressive Large Language Modeling. arXiv Prepr. arXiv2307.04340 2023. (44) Choudhary, K.; DeCost, B. Atomistic Line Graph Neural Network for Improved Materials Property Predictions. npj Comput. Mater. 2021, 7 (1), 185. (45) Jain, A.; Ong, S. P.; Hautier, G.; Chen, W.; Richards, W. D.; Dacek, S.; Cholia, S.; Gunter, D.; Skinner, D.; Ceder, G.; Persson, K. A. Commentary: The Materials Project: A Materials Genome Approach to Accelerating Materials Innovation. APL Mater. 2013, 1 (1). https://doi.org/10.1063/1.4812323. (46) Ward, L.; Dunn, A.; Faghaninia, A.; Zimmermann, N. E. R.; Bajaj, S.; Wang, Q.; Montoya, J.; Chen, J.; Bystrom, K.; Dylla, M.; Chard, K.; Asta, M.; Persson, K. A.; Snyder, G. J.; Foster, I.; Jain, A. Matminer: An Open Source Toolkit for Materials Data Mining. Comput. Mater. Sci. 2018, 152 (April), 60–69. https://doi.org/10.1016/j.commatsci.2018.05.018. (47) Ong, S. P.; Richards, W.", "page": 18, "position": 0}
{"chunk_id": "2410.06433v1_p18_c1", "doc_id": "2410.06433v1", "text": "to Accelerating Materials Innovation. APL Mater. 2013, 1 (1). https://doi.org/10.1063/1.4812323. (46) Ward, L.; Dunn, A.; Faghaninia, A.; Zimmermann, N. E. R.; Bajaj, S.; Wang, Q.; Montoya, J.; Chen, J.; Bystrom, K.; Dylla, M.; Chard, K.; Asta, M.; Persson, K. A.; Snyder, G. J.; Foster, I.; Jain, A. Matminer: An Open Source Toolkit for Materials Data Mining. Comput. Mater. Sci. 2018, 152 (April), 60–69. https://doi.org/10.1016/j.commatsci.2018.05.018. (47) Ong, S. P.; Richards, W. D.; Jain, A.; Hautier, G.; Kocher, M.; Cholia, S.; Gunter, D.; Chevrier, V. L.; Persson, K. A.; Ceder, G. Python Materials Genomics (Pymatgen): A Robust, Open-Source Python Library for Materials Analysis. Comput. Mater. Sci. 2013, 68, 314–319. (48) Song, Y.; Ermon, S. Generative Modeling by Estimating Gradients of the Data Distribution. Adv. Neural Inf. Process. Syst. 2019, 32. (49) Shi, C.; Luo, S.; Xu, M.; Tang, J. Learning Gradient Fields for Molecular Conformation Generation. In International conference on machine learning; PMLR, 2021; pp 9558–9568. (50) Dhariwal, P.; Nichol, A. Diffusion Models Beat Gans on Image Synthesis. Adv. Neural Inf. Process. Syst. 2021, 34, 8780–8794. (51) Grosse-Kunstleve, R. W.; Sauter, N. K.; Adams, P. D. Numerically Stable Algorithms for the Computation of Reduced Unit Cells. Acta Crystallogr. Sect. A Found. Crystallogr. 2004, 60 (1), 1–6.", "page": 18, "position": 1}
{"chunk_id": "2410.06433v1_p19_c0", "doc_id": "2410.06433v1", "text": "(52) Chen, C.; Zheng, J.; Chu, C.; Xiao, Q.; He, C.; Fu, X. An Effective Method for Generating Crystal Structures Based on the Variational Autoencoder and the Diffusion Model. Chinese Chem. Lett. 2024, 109739. (53) Xia, H.; Zheng, Z.; Li, Y.; Zhuang, D.; Zhou, Z.; Qiu, X.; Li, Y.; Lin, W.; Song, S. L. Flash-Llm: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity. arXiv Prepr. arXiv2309.10285 2023. (54) Jain, S. M. Hugging Face. In Introduction to transformers for NLP: With the hugging face library and models to solve problems; Springer, 2022; pp 51–67. (55) Hu, E. J.; Shen, Y.; Wallis, P.; Allen-Zhu, Z.; Li, Y.; Wang, S.; Wang, L.; Chen, W. Lora: Low- Rank Adaptation of Large Language Models. arXiv Prepr. arXiv2106.09685 2021. (56) Flam-Shepherd, D.; Aspuru-Guzik, A. Language Models Can Generate Molecules, Materials, and Protein Binding Sites Directly in Three Dimensions as Xyz, Cif, and Pdb Files. arXiv Prepr. arXiv2305.05708 2023. (57) Choudhary, K.; Garrity, K. F.; Reid, A. C. E.; DeCost, B.; Biacchi, A. J.; Hight Walker, A. R.; Trautt, Z.; Hattrick-Simpers, J.; Kusne, A. G.; Centrone, A. The Joint Automated Repository for Various Integrated Simulations (JARVIS) for Data-Driven Materials Design. npj Comput. Mater. 2020, 6 (1), 173. (58) Datta, J.; Koratkar, N.; Datta, D. Unlocking the Potential of Open-Tunnel Oxides: DFT-Guided Design and Machine Learning-Enhanced Discovery for next-Generation Industry-Scale Battery Technologies. Energy Adv. 2024, 3 (5). https://doi.org/10.1039/d4ya00014e. (59) Chen, C.; Ong, S. P. A Universal Graph Deep Learning Interatomic Potential for the Periodic Table. Nat. Comput. Sci. 2022, 2 (11), 718–728. (60) Gasteiger, J.; Becker, F.; Günnemann, S. Gemnet: Universal Directional Graph Neural Networks for Molecules. Adv. Neural Inf. Process. Syst. 2021, 34, 6790–6802. (61) Pan, H.; Ganose, A. M.; Horton, M.; Aykol, M.; Persson, K. A.; Zimmermann, N. E. R.; Jain, A. Benchmarking Coordination Number Prediction Algorithms on Inorganic Crystal Structures. Inorg. Chem. 2021, 60 (3), 1590–1603. (62) Gasteiger, J.; Giri, S.; Margraf, J. T.; Günnemann, S. Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules. arXiv Prepr. arXiv2011.14115 2020. (63) Court, C. J.; Yildirim, B.; Jain, A.; Cole, J. M. 3-D Inorganic", "page": 19, "position": 0}
{"chunk_id": "2410.06433v1_p19_c1", "doc_id": "2410.06433v1", "text": "(61) Pan, H.; Ganose, A. M.; Horton, M.; Aykol, M.; Persson, K. A.; Zimmermann, N. E. R.; Jain, A. Benchmarking Coordination Number Prediction Algorithms on Inorganic Crystal Structures. Inorg. Chem. 2021, 60 (3), 1590–1603. (62) Gasteiger, J.; Giri, S.; Margraf, J. T.; Günnemann, S. Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules. arXiv Prepr. arXiv2011.14115 2020. (63) Court, C. J.; Yildirim, B.; Jain, A.; Cole, J. M. 3-D Inorganic Crystal Structure Generation and Property Prediction via Representation Learning. J. Chem. Inf. Model. 2020, 60 (10), 4518–4535. (64) Sun, S.; Chen, Y.; Yu, J. High Throughput Screening of Organic Electrode Materials for Lithium Battery by Theoretical Method. J. Phys. Chem. C 2015, 119 (46), 25770–25777. (65) Dai, H.; Xu, W.; Chen, Y.; Li, M.; Chen, Z.; Yang, B.; Mei, S.; Zhang, W.; Xie, F.; Wei, W.; Guo, R.; Zhang, G. Narrow Band-Gap Cathode Fe3(PO4)2 for Sodium-Ion Battery with Enhanced Sodium Storage. Colloids Surfaces A Physicochem. Eng. Asp. 2020, 591 (February). https://doi.org/10.1016/j.colsurfa.2020.124561. (66) Li, W.; Huang, C. Transition Metal Oxides and Transition Metal Sulfides as Cathodes for Magnesium-Ion Batteries: Current Status and Modification Strategies. Mater. Today Energy 2024, 101510. (67) Wang, J.; Handoko, A. D.; Bai, Y.; Yang, G.; Li, Y.; Xing, Z.; Ng, M.-F.; Seh, Z. W. High-", "page": 19, "position": 1}
